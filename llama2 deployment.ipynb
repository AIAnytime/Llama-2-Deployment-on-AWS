{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0681d22-5c3e-4122-9cdd-b958066216fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.157 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0.1 which is incompatible.\n",
      "sparkmagic 0.20.5 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "sparkmagic 0.20.5 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \"sagemaker>=2.175.0\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab08a37e-0cf8-45b2-9932-86f122aff53e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::509247169753:role/service-role/SageMaker-LLMdeployment\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15948363-300c-44b3-a456-d217e2fd0c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi0.9.3-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"0.9.3\"\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cb56b8-34ae-4225-bea7-899c48739acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"NousResearch/Llama-2-7b-chat-hf\", # model_id from hf.co/models\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(2048),  # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(4096),  # Max length of the generation (including input text)\n",
    "  'MAX_BATCH_TOTAL_TOKENS': json.dumps(8192),  # Limits the number of tokens that can be processed in parallel during the generation\n",
    "  'HUGGING_FACE_HUB_TOKEN': json.dumps(\"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\")\n",
    "}\n",
    "\n",
    "# check if token is set\n",
    "assert config['HUGGING_FACE_HUB_TOKEN'] != \"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\", \"Please set your Hugging Face Hub token\"\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e41ced-450f-4352-b1a2-281d8e524e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc3bc9d-ae0a-4cdb-b3e4-18c85b321c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_llama2_prompt(messages):\n",
    "    startPrompt = \"<s>[INST] \"\n",
    "    endPrompt = \" [/INST]\"\n",
    "    conversation = []\n",
    "    for index, message in enumerate(messages):\n",
    "        if message[\"role\"] == \"system\" and index == 0:\n",
    "            conversation.append(f\"<<SYS>>\\n{message['content']}\\n<</SYS>>\\n\\n\")\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            conversation.append(message[\"content\"].strip())\n",
    "        else:\n",
    "            conversation.append(f\" [/INST] {message['content'].strip()}</s><s>[INST] \")\n",
    "\n",
    "    return startPrompt + \"\".join(conversation) + endPrompt\n",
    "\n",
    "messages = [\n",
    "  { \"role\": \"system\",\"content\": \"You are a friendly and knowledgeable vacation planning assistant named Clara. Your goal is to have natural conversations with users to help them plan their perfect vacation. \"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd5c622-0b1f-45d7-95c1-641e2c84fdee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Oh, wow, I'm so glad you asked! üòä There\n"
     ]
    }
   ],
   "source": [
    "instruction = \"Give me some ideas what to do when I am free?\"\n",
    "messages.append({\"role\": \"user\", \"content\": instruction})\n",
    "prompt = build_llama2_prompt(messages)\n",
    "\n",
    "chat = llm.predict({\"inputs\": prompt})\n",
    "\n",
    "print(chat[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258fe3aa-03ed-4505-91af-b307cc3ba5da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.6,\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_k\": 50,\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"repetition_penalty\": 1.03,\n",
    "        \"stop\": [\"</s>\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6061f51-9a03-4262-b851-4c1ea4a9cd67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = llm.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21240687-37c7-47d5-8740-08b7c53d1c86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ah, a perfect question! There are so many fun and exciting things to do on vacation, and it really depends on your interests and preferences. üòä\n",
      "\n",
      "Have you considered exploring local culture and history? Many destinations have fascinating museums, galleries, and historical sites that offer a glimpse into the area's rich heritage. For example, if you're in Europe, you could visit famous landmarks like the Eiffel Tower in Paris or the Colosseum in Rome. Or, if you're in Asia, you could learn about the ancient civilizations of China or Japan.\n",
      "\n",
      "Another great option is to experience the local cuisine. Each destination has its own unique flavors and dishes, and food tours are a great way to sample the local flavors. You could try street food in Bangkok, taste wine in Tuscany, or indulge in seafood in Maine. üçΩÔ∏è\n",
      "\n",
      "If you're looking for something more adventurous, there are plenty of outdoor activities to choose from. Hiking, biking, and kayaking are great ways to explore the natural beauty of a destination. Or, if you're feeling brave, you could try something new like skydiving or rock climbing. üèûÔ∏è\n",
      "\n",
      "Of course, no vacation is complete without some relaxation time. Many destinations have beautiful beaches, spas, and wellness centers where you can unwind and recharge. You could also try yoga or meditation to help you relax and find inner peace. üõãÔ∏è\n",
      "\n",
      "I hope these ideas give you some inspiration for things to do on your vacation! What are your interests, and how can I help you plan the perfect trip? üòä\n"
     ]
    }
   ],
   "source": [
    "print(response[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341dbc2-6f12-412d-9dc2-1eb8f1830a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
